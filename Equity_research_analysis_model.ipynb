{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1b41dd8",
   "metadata": {},
   "source": [
    "# Installing Dependencies and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40eb1e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d24935",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3288798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c315d1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(\"New Text Document.txt\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "253e5cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This Python code outlines a complete process for training a convolutional neural network (CNN) model for image classification using TensorFlow and Keras. It demonstrates importing data, pre-processing images, creating and training a model, and then evaluating its performance. Here's a detailed breakdown of the major components and steps involved, illustrated with figures for clearer understanding:\\n\\n### 1. Import Libraries\\nThe script starts by importing all necessary Python libraries such as `numpy`, `cv2` (OpenCV for image operations), `os` (for file operations), `tqdm` (for progress bars), `sklearn` for model splitting, `matplotlib` for plotting, and several components from `tensorflow.keras` for building and training the neural network.\\n\\n### 2. Model Settings\\nVariables are initialized to configure the paths, ratios for splitting the data, image dimensions, batch size, and training parameters like number of epochs and steps per epoch.\\n\\n### 3. Import Data\\nImages and their labels (classes) are loaded from the specified directory. The images are resized to a consistent dimension that is required by the model (32x32 pixels).\\n\\n**Figure 1: Import Data**\\n![Data Import Process](https://via.placeholder.com/500x300?text=Data+Import+Process)\\n\\n### 4. Split Dataset\\nThe dataset is divided into training, validation, and test sets based on the specified ratios. This step is crucial for training the model on one portion of the data and validating its performance on unseen data.\\n\\n**Figure 2: Dataset Splitting**\\n![Dataset Splitting](https://via.placeholder.com/500x300?text=Dataset+Splitting)\\n\\n### 5. Pre-Processing\\nImages are converted to grayscale, histogram equalization is applied to enhance the image contrast, and then normalized by dividing by 255. This standardizes the input data and helps in speeding up the learning process.\\n\\n**Figure 3: Image Pre-Processing**\\n![Image Pre-Processing](https://via.placeholder.com/500x300?text=Image+Pre-Processing)\\n\\n### 6. Data Augmentation\\nThis step involves artificially augmenting the training data using various transformations like shifts, rotations, and zooms to make the model robust to different orientations and scales of the input images.\\n\\n**Figure 4: Data Augmentation**\\n![Data Augmentation](https://via.placeholder.com/500x300?text=Data+Augmentation)\\n\\n### 7. Model Architecture\\nA CNN model is created with alternating convolutional and max pooling layers, dropout layers for regularization, and dense layers for classification. This architecture is typical for image classification tasks.\\n\\n**Figure 5: CNN Architecture**\\n![CNN Architecture](https://via.placeholder.com/500x300?text=CNN+Architecture)\\n\\n### 8. Training\\nThe model is trained using the augmented data. The training process involves feeding the batches of images to the model and adjusting the weights to minimize the loss function.\\n\\n**Figure 6: Training Process**\\n![Training Process](https://via.placeholder.com/500x300?text=Training+Process)\\n\\n### 9. Performance Evaluation\\nAfter training, the model's performance is evaluated on the test set. Loss and accuracy graphs are plotted to visualize the training and validation process across epochs.\\n\\n**Figure 7: Model Evaluation**\\n![Model Evaluation](https://via.placeholder.com/500x300?text=Model+Evaluation)\\n\\n### 10. Save Model\\nFinally, the trained model architecture and weights are saved to files. This allows the model to be reloaded later for further use without needing to retrain.\\n\\n**Figure 8: Saving the Model**\\n![Saving the Model](https://via.placeholder.com/500x300?text=Saving+the+Model)\\n\\nThis code provides a comprehensive pipeline for training a neural network model for image classification tasks, which can be adapted and expanded based on specific needs and data characteristics.\\n\\n\\n\\n\\nIEEE scholarship recommendation\\nFYP Project IC-Hiruni akka\\nSubject GPA\\n\\nrx tx adc\\n\\n\\nIEEE STARLINK\\n\\nIT-deputy director ministry of education southern province \\nDellava Kanishta Vidyalaya â€“ Mr.jayawardana â€“ 0701213931 â€“ 0775447016 - \\nHappitiya kan â€“ Mrs.dammika â€“ 0705897934 \\n\\nTower are\\nDellawa tower eken eliye â€“ \\nSlt router ekakin shape\\nDialog na\\nSchool â€“ 452\\n1-13, Mishra\\nIt centre â€“ machine 24k \\nSwitch ekak â€“ 10 lakh project â€“ area 6 7 k\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c58bcace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'New Text Document.txt'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1df559f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "loader = CSVLoader(\"movies.csv\")\n",
    "data = loader.load()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "358b58a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'movies.csv', 'row': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2326b36",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'show'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'show'"
     ]
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3364d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
